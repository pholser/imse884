LP background
=====
max z_LP = c^T * x
s.t. Ax <= b
     x >= 0

c, x in R^n
A in R^(m x n)
b in R^(m x 1)

Integer program:
max z_IP = c^T * x
s.t. Ax <= b
     x in Z^n_+   (x >= 0 and integer)

c in R^n
A in R^(m x n)
b in R^(m x 1)

Is there a relationship between z_LP and z_IP?
z_LP >= z_IP

In general, no poly-time algo to solve an IP.

Treat the LP as a linear relaxation of the IP
(remove the integrality restrictions).

e.g.
max 5x_1 + 2x_2
s.t. 3x_1 + x_2  <= 10
     2x_1 + 3x_2 <=  8
     x_1, x_2 >= 0 and integer

Linear relaxation:
max 5x_1 + 2x_2
s.t. 3x_1 + x_2  <= 10
     2x_1 + 3x_2 <=  8
     x_1, x_2 >= 0

Convex problems easy to solve; non-convex
problems not so much.

-- Convexity of function
    f(x) is convex
    <->
    forall x_1, x_2 in dom(f), forall lambda in [0, 1]:
        f(lambda * x_1 + (1 - lambda) * x_2)
        <=
        lambda * f(x_1) + (1 - lambda) * f(x_2)

-- Convexity of set
    S subset-of R^n is convex
    <->
    forall x_1, x_2 in S, forall lambda in [0, 1]:
        lambda * x_1 + (1 - lambda) * x_2 in S

-- feasible region of an LP is a convex set;
    IP not so much, unless:
    -- feasible region is a singular point
    -- feasible region is empty set

The convex hull of S is the intersection of all
convex sets that contain S.

Can the linear relaxation of an IP be feasible,
but the IP infeasible?
--> max x_1 + x_2
    s.t. x_1 <= 1/2
         x_1 >= 1/4
    (linear relaxation unbounded here.)
--> narrow triangle that never contains integer points

Extreme points of feasible region of LP:
-- If there is an optimum, it's at a corner point
   -- As long as LP not infeasible or unbounded
-- Also called basic feasible solutions (BFS)

Degeneracy:
-- > 1 basis corresponding to a single BFS
-- One of the basic vars takes zero
    (or takes on lower/upper bound of var)

Degeneracy created by:
-- Redundant constraints
-- > n hyperplanes meeting at a point in n
    dimensions

Simplex method: move from corner to corner,
till optimum found.

e.g. max 5x_1 + 3x_2
     s.t. x_1 <= 4
          -x_1 + x_2 <= 6
          3x_1 + 2x_2 <= 18
          x_1, x_2 >= 0

z   x_1   x_2   s_1   s_2   s_3    RHS
--------------------------------------
1    -5    -3     0     0     0      0
0     1     0     1     0     0      4  s_1
0    -1     1     0     1     0      6  s_2
0     3     2     0     0     1     18  s_3

x_1 leaves
s_1 enters: 4/1 min

z   x_1   x_2   s_1   s_2   s_3    RHS
--------------------------------------
1     0    -3     5     0     0     20
0     1     0     1     0     0      4  x_1
0     0     1     1     1     0     10  s_2
0     0     2    -3     0     1      6  s_3

x_2 leaves
s_3 enters: 6/2 min

z   x_1   x_2   s_1   s_2   s_3    RHS
--------------------------------------
1     0     0    1/2    0   3/2     29
0     1     0     1     0     0      4  x_1
0     0     0    5/2    1   -1/2     7  s_2
0     0     1   -3/2    0    1/2     3  x_2

z* = 29, x_1 = 4, x_2 = 3, s_2 = 3/2, s_1 = 0, s_3 = 0

If this were an IP, and we ended up with a non-integer
soln, we'd need to cut the space down.

Add a constraint: x_1 + x_2 <= 5
Re-solve as LP
Add constraint to tableau
Re-establish basis...
Check optimal; if not, pivot, maybe dual simplex


Duality in LP
=====

primal:
e.g.
max c^T * x
s.t. Ax <= b
     x >= 0

dual:
min b^T * y
s.t. A^T * y >= c
    y >= 0

c^T * x <= b^T * y   # weak duality

Strong duality theorem:
If there is an optimum to the primal,
there is an optimum to the dual, and
    c^T * x^* = b^T * y^*

Complementary slackness:
For a corner-point soln:
If x_i is basic, e_i is non-basic
    (e = surplus var)
If s_i is basic, y_i is non-basic
    (s = slack var)

    x * e = 0
    s * y = 0

Reduced costs/shadow prices/dual prices: values in
objective row of simplex tableau above the slacks

Sensitivity analysis

Better off with simplex method on linear relaxations
of IP, as opposed to interior-point methods
(why?)

Simplex may require exponential time in pathological
cases.
There are polynomial-time algos for LP now
(interior-point methods)

if A then B:
T     T   -->  T  # Assume A true; show B must be true
T     F   -->  F
F     T   -->  T
F     F   -->  T

A iff B:
T     T   -->  T  # Assume A true; show B must be true
T     F   -->  F
F     T   -->  F
F     F   -->  T  # Assume B true; show A must be true

Proof by contradiction of "if A then B":
-- Assume A is true; assume B is false.
-- What follows from this? Need to show that
    this leads to a contradiction, and so B
    must be true

Contrapositive: if ~B, then ~A
(A -> B is equivalent to ~B -> ~A)

Converse: if B, then A
Inverse: if ~A, then ~B


Graph: set G = (V, E)
V = vertices, E = edges

Directed edges or undirected edges

Graph as substructure for building an IP

Node-node adjacency matrix representation
(A[x, y] = 1 if nodes x and y are connected via
an edge, else ___? (sometimes 0, sometimes -(degree)))

   A   B   C   D
A  0   1
B  1   0
C          0
D              0

(symmetric for undirected graph)

Node-arc incidence matrix:
    (A,B) (A,C) ...
A
B
C
C

Exactly two ones in every column
Usually more edges than nodes -> more storage req'd

Directed node-arc rep:
 1 for flow-out
-1 for flow-in
All columns sum to zero --> unimodular matrix
-- not linearly independent
    --> cross off bottom row
        --> basis: tree (graph w/no cycles)
            fast pivots (network simplex method)
-- If this is only set of constraints, and RHS
    of constraints are integers, then you'll get
    an integer soln always

Paths

Discovered tree

Clique of a graph: subgraph that has all possible
edges (every node has an edge to every other node)
-- k_n, where n is # of nodes in clique
(complete graph)
# edges: C(n, 2)

Complement of a graph:
graph with same set of vertices, but with edges
where there weren't edges in original graph, and
the original edges removed.

Bipartite graph:
where vertices are partitioned into two sets, and
there are no edges between two nodes in the same
partition.
These come up in transportation models a lot--
-- sources vs. destinations
-- assignment problems: tasks to workers...
-- no odd cycles

Matching problem:
-- sum[i]( x_ij ) <= 1 forall j
-- sum[j]( x_ij ) <= 1 forall i

Node packing problem:
find a set of nodes of maximum cardinality such that
no node is incident with the same edge (or arc)

Set packing problem:
Given a universe U and a family S of subsets of U,
find a collection C of sets in S, whose cardinality is
maximized, such that all sets in C are pairwise
disjoint.

O(f(n)), Omega(f(n)), Theta(f(n))
Polynomial-in-n time

Implicit enumeration of binary IP solutions:
exponential in # vars

NP: set of all problems whose solutions can be verified
in polynomial time
NP-complete: set of NP problems that can be transformed
into each other in polynomial time.
NP-hard: at least as hard as the hardest problems in NP
(don't have to be elements of NP)

IP are NP-complete problems

Two important sets in an IP:
-- Convex hull of feasible integer points
-- Region induced by the (linear relaxation of)
    the constraints

IP:
max c^T * x
s.t. Ax <= b
    x >= 0

Let P = { x in Z^n_+ : Ax <= b }
(countable set of points)
Let P_LR = { x in R^n_+ = Ax <= b }
    (linear relaxation set)
Let P_CH = convex hull of P

Every LP has an optimum, if it does, at an
extreme point/BFS/corner point

If we change the IP to:
max c^T * x
s.t. x in P_CH,
then an optimum will be at a corner point of
P_CH

Main idea: To LR, add a bunch of other constraints
such that we whittle the feasible region down in
this way such that we obtain corner points that
are integer --> cutting planes

P_CH and P_LR are polyhedra
{ x in R^n : Ax <= b }
* All polyhedra are convex.

Convex set that is not a polyhedron: circle

Adding cutting planes iteratively, it introduces
the risk of introducing degeneracy.

backwards-e == "such that"


Branch-and-bound for IP
=====
-- graphical
-- knapsack

0) Initialization: Create a search tree where the nodes are
LP relaxation problems. The tree starts with one node (the root),
which is the relaxation of the original LP.
Set Z*_ip = -inf.

While there exists at least one unfathomed leaf node:
-- Solve the LP relaxation of this node with solution
    z_LP and x_LP, then perform one of the following
    four steps:

1) If x_LP is integer, then an integer solution has been
found. If z_LP > z*_IP, then set z*_IP to z_LP and save
x_LP as the corresponding soln; fathom this node.

2) If z_LP <= z*_IP, then fathom this node (known as the
bounding portion).

3) If the LP relaxation is infeasible, then fathom this
node.

4) If z_LP >= z*_IP and x_LP is not integer, then there exists some
p < x_i < p+1 where p in Z. Create two new nodes to the tree;
these nodes are the children of the node that we are working on.
The LP relaxation problem for one of these child is the
LP relaxation of the parent with an additional constraint of
x_i <= p. The other child node also has the parent's LP relaxation
and includes the constraint x_i >= p + 1.

Can traverse the tree:
-- breadth-first
    -- left child first
    -- right child first
-- depth-first
    -- left child first
    -- right child first
-- best child
-- best bound

What var to branch on?
-- for exam: choose lowest index candidate var

Need to be able to traverse from leaf thru ancestry,
to pick up all the constraints

Track basis, z-value, ...

Running time for a branch-and-bound IP algo:
-- # branches gets large quickly
-- # nodes at level n: 2^n

0-1 knapsack problems:
max c^T * x
s.t. a^t * x <= b
    x in {0, 1}^n
    a >= 0

e.g.
max 5x_1 + 8x_2 + 12x_3 + 6x_4 + 3x_5
s.t. x_1 + 2x_2 + 4x_3 + 3x_4 + 3x_5 <= 9
    x_i in {0, 1}

c = values of items
a = weights of items
b = capacity of knapsack

2^n candidate solutions.

dual:
min 9y
s.t. y >= 5
     2y >= 8
     4y >= 12
     3y >= 6
     3y >= 3
     y >= 0

min ratio test: c_i/a_i

Add bounds between 0 and 1 on all the x_i.
Pivot on x_1 (max c_i/a_i)

z   x_1   x_2   x_3   x_4   x_5   s_i  RHS
==========================================
1    -5   -8    -12    -6    -5    0    0
0     1    2      4     3     3    1    9
   add constraint
      1                                 1

Set x_1 to upper bound, 1.
z now 5
Now move x_2 to its upper bound, 1
z now 13
...

greedily choosing stuff with best value/weight ratio
until you have to take a fractional amount, or you're
at (integer) capacity

If something's at its upper bound, negative is OK in
objective row of tableau; if at its lower bound, positive
OK.

If upper bound is lower than ratio test result, take
the upper bound as pivot

Branch-and-bound on above example, using best-child
strategy.

e.g.
max 5x_1 + 8x_2 + 12x_3 + 6x_4 + 3x_5
s.t. x_1 + 2x_2 + 4x_3 + 3x_4 + 3x_5 <= 9
    x_i in {0, 1}

Node root)
(1, 1, 1, 2/3, 0)
z = 29

Branch: node 1) x_4 <= 0 vs. node 2) x_4 >= 1

Best child:
Node 1): z = 27 (1, 1, 1, 0, 2/3)
Node 2): z = 28 (1, 1, 3/4, 1, 0)

Node 2 is best since z is greater.
Branch from here: node 3) x_3 <= 0, node 4) x_3 >= 1
Node 3): z = 22 (1, 1, 0, 1, 1)
    --> z_best = 22
Node 4): z = 27 (1, 1/2, 1, 1, 0)
Best child is a tie, choose node 5) for branch
Node 6):
...

Branching on non-fractional vars?

Choosing between vars to branch on?
-- HW: "cheat". Find whatever amounts to less work.


Advanced branching strategies:
With an IP of 100 vars, branching tree could get
to be 2^100 nodes

Best-child advantageous re: intelligently pruning
search space.

DFS advantageous re: memory management
randomly choose left/right

BFS: memory problems

Best-child: sorting children. Priority queue

The shape of the problem matters.
1) Feasibility problem
2) Optimality problem
3) Mixture of 1) and 2)

Random diving

-- If A and b are rational
-- If there is a feasible integer point
-- If LP unbounded
-- Then IP is unbounded

Pseudo-branching:

We would be branching on a basic var; never
a non-basic var (NBV would always be zero, an integer)

We know based on the reduced costs of NBV, which vars are
doing more or less harm in achieving optimality.

What if we branched on a BV based on some estimate of
reduced cost --> Pseudo-cost.

Gets a broader separation, where one child of the branch
improves a lot, the other doesn't --> hopefully fathom
larger chunk of tree.

No silver bullet, that will work well on every problem.

Strong branching:
-- n vars, assume they're binary; bad reduced costs
    call that set of vars S

root: branch on sum[x_i in S](x_i) = 0, and on
    sum[x_i in S](x_i) >= 1

Hopefully fathom one side or another quickly.

Or:
root: branch on sum[x_i in S](x_i) = n, and on
    sum[x_i in S](x_i) <= n - 1
where n is |S|

-- branch on var least close to integer
(CPLEX default)
    -- depends on the problem
        -- feasibility vs. optimality

Rules for branching:
1) Between all children, no feasible integer points
eliminated
2) Must remove linear relaxation of parent
3) Must eventually terminate with only integer
    extreme points
    -- End at a single integer point

Branching on polyhedra:
-- Each node with four children:
-- Only works for integer problems, not binary

Easton: Branching: easier and better than many other
techniques for solving IP
-- Sometimes helpful to invent hand-rolling branching
strategy for solving specific problems


Column generation:
When LP/IP has way more variables than constraints
-- Comes up a lot in crew scheduling problems

Idea: take the problem, cut it down to some reasonable
size involving fewer vars; introduce new columns as you
go
-- Don't add variables that would never pivot in

The overarching idea is that many linear programs are too large
to consider all the variables explicitly. Since most of the
variables will be non-basic and assume a value of zero in the
optimal solution, only a subset of variables need to be considered
in theory when solving the problem. Column generation leverages
this idea to generate only the variables which have the potential
to improve the objective function -- that is, to find variables
with negative reduced cost (assuming without loss of generality that
the problem is a minimization problem).

The problem being solved is split into two problems:
the master problem and the subproblem. The master problem is
the original problem with only a subset of variables being considered.
The subproblem is a new problem created to identify a new variable.
The objective function of the subproblem is the reduced cost of
the new variable with respect to the current dual variables,
and the constraints require that the variable obey the naturally
occurring constraints.

The process works as follows. The master problem is solved --
from this solution, we are able to obtain dual prices for each of
the constraints in the master problem. This information is then
utilized in the objective function of the subproblem.
The subproblem is solved. If the objective value of the subproblem
is negative, a variable with negative reduced cost has been
identified. This variable is then added to the master problem,
and the master problem is re-solved. Re-solving the master problem
will generate a new set of dual values, and the process is repeated
until no negative reduced cost variables are identified.
The subproblem returns a solution with non-negative reduced cost,
we can conclude that the solution to the master problem is optimal.

e.g. Cutting stock problem.
Lots of wood planks of a particular length.
How to cut it into pieces of the desired lengths so as to
minimize the number of boards I need to cut

n pieces of wood, 52 ft. long.
Need pieces 6 ft., 8 ft., 10 ft. long

Demand for 6-ft pieces: 120
        8-ft          : 54
        10-ft         : 60

Let x_i = # of boards of type i, where I make a certain
set of cuts on the board

min x_1 + x_2 + x_3
s.t.
8x_1 + 0x_2 + 0x_3 = 120
0x_1 + 6x_2 + 0x_3 = 54
0x_1 + 0x_2 + 5x_3 = 60

current soln: (15, 9, 12)

Revised simplex tableau:

 c_B^T * B^(-1) * A_j - c_j  | c_B^T * B^(-1) * b
-------------------------------------------------
    A_j * B^(-1)             | B^(-1) * b

B^(-1) = [8 0 0; 0 6 0; 0 0 5]^(-1)
       = [1/8 0 0; 0 1/6 0; 0 0 1/5]
z = 36

Column gen: treat those as ridiculous cuts.
a) What about 3 6ft, 3 8ft, 1 10ft from each board?
b) What about 4 6ft, 0 8ft, 2 10ft from each board?

To decide whether such a new cut would be beneficial,
calc the reduced costs (c_B^T * B^(-1) * A_j - c_j)...
if it's making the cost cheaper, add it in.

(1 board added in each; cost of new column therefore == 1)
a) (1 1 1)[1/8 0 0; 0 1/6 0; 0 0 1/5] * [3 3 1] - 1
   = 43/40 - 1 = 3/40
b) -1/10

a) better:

min x_1 + x_2 + x_3 + x_4
s.t.
8x_1 + 0x_2 + 0x_3 + 3x_4 = 120
0x_1 + 6x_2 + 0x_3 + 3x_4 = 54
0x_1 + 0x_2 + 5x_3 +  x_4 = 60

Keep pricing in other columns, eliminate others

Branch-and-price: essentially column gen for IP
Start B-and-B tree at root node with LR of reduced problem
At node further down, you either have:
-- integer
   -- update z_IP; you now have a B^(-1)
   -- add columns
-- fractional
   -- < z_IP
       -- add columns
   -- >= z_IP
       -- branch
-- infeasible
   -- add columns

check out the slack for a given solution -- target reducing
these on column gen decisions

Matching in a graph:
set of edges such that there is at most one edge
adjacent to every node

Bipartite graphs cannot have odd cycles

Clique k_m in a graph is a complete subgraph of a graph,
whose number of vertices = m
-- # edges: C(m, 2)

Independent set of vertices:
-- Select vertices such that no two vertices are
    adjacent.

Packing, covering


IP modeling:
HW2:
-- problem 1, do it in Excel
-- problem 2, do it in whatever
-- problem 3, do it in whatever
    -- a) minimize sum of all completion times
        -- shortest processing time first
    -- b) minimize max finish time
-- problem 4, do it in whatever
-- problem 5, do in in OPL

Modeling TSP:
-- n cities
-- distances between each city pair (i, j)
-- Visit all the cities once so as to minimize
    the total distance traveled.

One possible formulation:
Decision vars:
1) x_ij = 1 if tour includes arc from i to j
        = 0 else
2) x_ik = 1 if city i is the k'th city on the tour
        = 0 else
3) x_ijk = 1 if city i is the (k-1)'th city and
    city j is the k'th city.
         = 0 else

Example tour with five cities: 1-2-3-5-4-1

3) constraints:
     Above, we have x_121 = 1,
     x_232 = 1,
     x_353 = 1,
     x_544 = 1
     x_415 = 1

# There is only one k'th arc in the tour
* sum[i, j]( x_ijk ) = 1, forall k

# No self-visits
* x_iik = 0, forall i, k     # n^2 constraints
    With one constraint: sum[i, k]( x_iik ) = 0

# One exit out of each city
* sum[j, k]( x_ijk ) = 1, forall i

# One entry into each city
* sum[i, k]( x_ijk ) = 1, forall j

# Start and end at node 1
* sum[j]( x_ij1 ) = 1,
    sum[]( x_i1n ) = 1

# Flow-in == flow-out at each node
...?


2) constraints
    Above, we have x_11 = 1
        x_22 = 1
        x_33 = 1
        x_54 = 1
        x_45 = 1
        x_16 = 1

# Exactly one city is the k'th city
sum[i]( x_ik ) = 1, forall k

# Every city visited exactly once
sum[k]( x_ik ) = 1, forall i

Let d_ij = distance between cities i and j
Let var y_ij = 1 if cities i and j are adjacent in tour
     (i -> j)

# e.g.
x_11 = 1 /\ x_32 = 1 --> y_13 = 1
    # truth-table this for all vals to generalize

x_11   x_32   y_13
==================
  0     0      0
  0     0      1
  0     1      0
  0     1      1   x
  1     0      0
  1     0      1   x
  1     1      0   x
  1     1      1   <- forced

(1 - x_11) + x_32 + y_13 <= 2
x_11 + (1 - x_32) + y_13 <= 2
x_11 + x_32 + (1 - y_13) <= 2

# in general:
(1 - x_ik) + x_j_(k+1) + y_ij <= 2
    forall i, j; forall k s.t. k <= n - 1
x_ik + (1 - x_j_(k+1)) + y_ij <= 2
    forall i, j; forall k s.t. k <= n - 1
x_ik + x_j_(k+1) + (1 - y_ij) <= 2
    forall i, j; forall k s.t. k <= n - 1

min sum[i, j]( d_ij * y_ij )

Lots of constraints!


1) x_ij = 1 if tour includes arc from i to j
        = 0 else

min sum[i, j]( d_ij * x_ij )

# leave every node exactly once
sum[i]( x_ij ) = 1, forall i

# enter every node exactly once
sum[j]( x_ij ) = 1, forall j

# no self-visits
sum[i]( x_ii ) == 0, forall i

Subtours (e.g. 1-2-1, 3-4-5-3 out of cities {1, 2, 3, 4, 5})

-- Subtours satisfy the above constraints.
-- Must eliminate these possibilities.

e.g.
x_34 + x_45 + x_53 + x_43 + x_54 + x_35 <= 2

sum[i, j: i, j in {1..4}]( x_ij ) <= 3

# in general:
let S be a subset of nodes, 2 <= |S| <= floor(n/2)
sum[i in S]( sum[j in S] ( x_ij ) ) <= |S| - 1
    forall S subset-of V s.t. 2 <= |S| <= floor(n/2)
    # 2^(n-1) of these constraints!
    # find a soln without these, then add in subtour constraints

Lazy constraints:
-- those constraints that don't really contribute

Remove such constraints.
If you find a soln in the reduced-constraint problem,
you can test it against the lazy removed constraints;
if there are violations, need to add violated
constraints back to problem, and resolve.
Lots of constraints increase basis; more challenging
to solve.

With TSP, you have a zillion constraints (expo in #cities),
subtour constraints, etc...

Use these in problems with:
-- lots of constraints
-- fast method for identifying vios on constraints

Modeling: disjunctive constraints:
e.g. with integer vars:
    min (x - 2)^2
Hint: make it piecewise linear
Use a linear approximation for different slices of
the function

  x     f(x)
-------------
  0      4
  1      1
  2      0
  3      1
  4      4
  5      9

For x = 2.5, f(x) on the line between (2, 0) and (3, 1)
Convex combination: x = lambda * x_1 + (1 - lambda) * x_2
                  f(x) = lambda * f(x_1) + (1 - lambda) * f(x_2)

Lambdas for each piecewise segment:
    lambda_0, ..., lambda_5

lambda_i >= 0
sum[i]( lambda_i ) == 1

to get to f(2.5):

min 4 * lambda_0 + 1 * lambda_1 + 0 * lambda_2
    + 1 * lambda_3 + 4 * lambda_4 + 9 * lambda_5
s.t. the above.

But, do extra to ensure that you get only
two non-negative lambdas.

Add binary vars u_1, ..., u_5, so that
u_1 sits between lambda_0 and lambda_1....

sum[i]( u_i ) == 1

e.g. lambda_0, lambda_1, u_1
0     0    0   --> ok
0     0    1   --> x
0    >0    0   --> ok
0    >0    1   --> ok
>0    0    0   --> ok
>0    0    1   --> x
>0   >0    0   --> x
>0   >0    1   --> ok

how to express a constraint that captures this truth table?
(1 - lambda_i) + (1 - lambda_(i+1)) + u_i <= 2

Useful for expressing nonlinear constraints, objective
as if they were linear.

e.g. sports scheduling
Double robin-round tournament
n teams, 2n - 2 slots

Kansas State
West Virginia
Texas Tech

Decision vars:
The solution looks like "team t comes to facility f
to play at time t"
Let x_ijk = 1 if team i plays at team j in slot k

e.g. x_{tt,ksu,12} = 1

constraints:
# Every team occupies right number of slots
sum[j]( x_ijk ) + sum[j]( x_jik ) = 1
    forall k, forall i
(obviates first constraint)

# Every team plays every other team twice,
# once on road, once at home.
sum[k]( x_ijk ) = 1 forall i, forall j != i
sum[i, k]( x_iik ) == 0

# Need separation between matchups of two of same teams
x_{TT,KSU}1 = 1
-->
sum[i in 2..6])( x_{KSU,TT} ) == 0

x_{KSU,TT}1 = 1
-->
sum[i in 2..6])( x_{TT,KSU} ) == 0

sum[k in m..m+5]( x_ijk + x_jik ) <= 1
    forall i, forall j != i, forall m in 1..2n-7

# At most two home games in a row for a team
x_{TT,KSU}_k + x_{WV,KSU}_(k+1) + x_{BAY,KSU}_(k+2)
    <= 2

sum[i, k in m..m+2]( x_ijk ) <= 2
    forall j, forall m in 1..2n-4

# Same for away games

# KSU must be away in slot 14 due to concert
sum[j]( x_{KSU,j,14} ) == 1, forall j != KSU

# Equal number of weekends at home
(slots 2, 4, 6, ..., 18)
(every team gets at least four weekend games)

# TV usually sets objective(s)
there are A and B games
-- A-game: two top-25 teams
    (Okla, Tech, WV, KU, BAY)
-- B-game: WV at TEX, KU at KSU, ...

Goal: have at least 2 B-games or 1 A-game in
every slot.

Let y_k = 1 if slot has a good matchup, 0 else.

Come up with constraints and objective to match.


e.g. Cancer treatment
-- Tumor in brain
-- Would like to kill the tumor with radiation
-- Aim a beam thru head, person perfectly still
-- May kill tumor, but other tissue along way
-- Some parts of brain, you must not go thru.

Where to align gamma knife, how much radiation to
send thru that alignment, how many shots to take?

Discretize the brain into points (1 mm^3?)
p_ijk = 1 if coord (i,j,k) has cancer, 0 else

Let x_{theta,phi},{x_1,y_1,z_1} =
    radiation setting >= 0
Let y_{theta,phi,x_1,y_1,z_1} = 1 if shot beam, 0 else
    still discretizing the potential angle space

-- Amt of radiation will be less in interior parts of brain
-- Radiation beam will have an effect on cells not in the
    beam's path

Sparsity of IP matrices
--> phrase constraints in terms of the non-zeros

To kill a cancer cell at p_ijk, you need at least a certain
amt of radiation to hit it.

Good model formulations:
This is a tough one: there are a number of equivalent models,
some solve faster than others. It is difficult to quantify a
good model and we will cover this throughout the semester.

One way frequently used to tighten models is to remove
redundant constraints, adding logical inequalities, fixing variables.

For instance:

max 5x_1 + 7x_2 + 3x_3 + x_4 + x_5 + x_6
s.t.:
    10x_1 + 7x_2 + 3x_3 <= 15   (logi imp)
     5x_1 + 2x_2 +  x_3<= 5	    (Red)
     x_5 + x_6 <= 1             (log imp)
     x_4 + x_6 <= 1
     x_4 + x_5 <= 1
     7x_3 - x_4 - x_5 - x_6 <= 5.3 (fixing).
    x1,x2,x3,x4,x5,x6 {0,1}

Can reduce to:
max 5x_1 + 7x_2 + 3x_3 + x_4 + x_5 + x_6
s.t.:
    10x_1 + 7x_2 + 3x_3 <= 15
      x_4 +  x_5 +  x_6 <= 1
      x_1 <= x_2
    x1,x2,x3,x4,x5,x6 {0,1}

So the soln is immediate.

CPLEX preprocessing: attempt to remove constraints,
vars, etc. to get to something that makes sense.

Can tell you size of reduced problem


Polyhedral theory
=====

P = {x in Z+^n : Ax <= b}
P_LR = {x in R+^n : Ax <= b}
P_ch = convex-hull(P)

e.g.
max 5x_1 + 2x_2
s.t.
10x_1 + 2x_2 <= 23
4x_1 + 2x_2 <= 13
x_i >= 0, x_i in Z_n

x* = (5/3, 19/6)

Here, P = all integer points in the feasible region
of the linear relaxation P_LR: {(0, 0), (0, 1), ...}

P_LR = feasible region of linear relaxation.

P_ch = convex hull of P, intersection of all convex sets
that contain P.

Cutting plane/separation problem:
Add a new constraint that cuts off the optimum of
LR, but not any integer points.
Does there exist such a constraint?
--> Branch and bound tree runs better.

If you're not at an optimal integer solution,
you can find such an inequality, adding cutting planes

Is the separation problem easy or NP-complete?
--> NP-complete

--> The cutting plane to use is the IP objective function.

If we can express the convex hull, we're done --
get a corner extreme point that's integer.

Which inequalities induce P_ch?

Dimension of a set of q vectors: the number of linearly
independent vectors in the set.
LI: v_1, ..., v_q in R^n are LI iff the unique soln to
sum[i in 1..q]( lambda_i * x_i ) = 0
is lambda_i = 0 forall i

Do row reduction on set of vectors, trying to make 1
down diagonal: number of 1's down diagonal == dimension

What is the dimension of P_ch?
-- pick a feasible point in P_ch, how many feasible
directions can you go?

Affine independence:
Points x_1, ..., x_q in R^n are affinely independent
iff the unique solution to
sum[i in 1..q]( lambda_i * x_i ) == 0
and
sum[i in 1..q]( lambda_i ) == 0
is lambda_i == 0 forall i = 1..q

Dimension of a space == max # of affinely independent
points minus 1.

Theorem: Equivalent statements:
-- Points x_1, ..., x_k are affinely independent
-- Vectors x_1 - x_k, x_2 - x_k, ..., x_(k-1) - x_k are
    linearly independent
-- (x_1, 1), ..., (x_k, 1) are linearly independent.

Point as column in matrix.
Add row of 1's for lambdas in matrix

I can choose some set of affinely independent points in
my set. How do I know whether I've found a maximal set
of such points, so that I'm describing the dimension of
the set of points P_ch?

I may know, e.g. dim(P_ch) >= 2
If I have dim(P_ch) <= 2 also, then I know my
exact dimension of P_ch --> 2

Can't ever have more dimensions than # variables.
If you are at # variables: full-dimensional.

dim(single-point set) == 0
dim(empty set) == -1 (by convention)

A^T * x <= b is a half-space
A^T * x == b is a hyperplane

To turn a half-space into a hyperplane:
A^T * x + s = b

Difference between half-space and hyperplane
is the view you're looking at it as.

Polyhedron: has a finite number of half-spaces.

Every LP formulation is a polyhedron.

P_ch is a polyhedron also.
P_LR and P_ch as polyhedra.

Circle isn't a polyhedron. No linear equalities.
Infinite number of lines, disqualified b/c inf. #

Polyhedra can be expressed in terms of
extreme points and extreme directions.

Bounded polyhedron --> no extreme ray

If we have a polyhedron Ax <= b, we can define
the set A^= * x <= b^=  in term of
I = set of constraints

A^=, b^=
=
{ i in I : Ax = b, forall x in Ax <= b }

(the set of tight constraints)

n = dim(Ax <= b) + dim(A^+, b^=)

e.g.
P defined by:
x_1 + x_2 + x_3 <= -5
-x_1 - x_2 - x_3 <= -5
-x_1 <= 0
-x_2 <= 0
-x_3 <= 0
x_3 <= 3
x_i are integers

Each point that satisfies this must satisfy
x_1 + x_2 + x_3 == 5

dim(A^=, b^=) == 1

Adding x_2 >= 5 --> only (0, 5, 0) satisfies.
Then dim(A^=, b^=) == 3

A polyhedron of dimension n, where dim(A^=, b^=)
is 0, is full-dimensional.

The constraints of a polyhedron Q can be partitioned into
A^(<=), b^(<=) and A^=, b^= where every x in Q satisfies
A^=, b^= and there exists at least one x in Q such that
A^(<=), b^(<=). For convenience, let M^= be the set of
row indices that fall into A^=, b^= and M^(<=) be the
set of row indices that fall into A^(<=), b^(<=).

A point x in Q is called an inner point of Q if
A_j * x_i <= b_j for all A_j, b_j in A^(<=), b^(<=).

A point x in Q is called an interior point of Q if
Ax < b.

Every full-dimensional polyhedron has an interior point.

Original constraints:
Ax <= b
a^T * x <= b

An inequality alpha^T * x <= beta is valid for P_ch if
every x in P_ch satisfies alpha^T * x <= beta.

A valid inequality is trivial if it is implied by the
bounds of the problem.

e.g.
max 5x_1 + 2x_2
s.t.
10x_1 + 2x_2 <= 23
4x_1 + 2x_2 <= 13
-x_1 <= 0, -x_2 <= 0 and integer.

* x_1 <= 200: valid
* x_1 <= 2: valid
* 2x_1 <= 4: valid (same as one before)
* x_1 <= 1: invalid ((2, 0) is feasible)
* x_1 + 2x_2 <= 9: invalid ((0, 6) is feasible)
* 5x_1 + 2x_2 <= 12: invalid ((1, 4) is feasible)
* x_1 - x_2 <= 2: valid
* x_3 >= 0: valid

Figuring out whether an inequality is valid or not
is hard, generally.

Let alpha^T * x <= beta and gamma^T * x <= omega
be two valid inequalities. They are equivalent iff there
exists some lambda >= 0 such that lambda * alpha = gamma
and lambda * beta = omega.

If there exists lambda such that lambda * alpha >= gamma
and lambda * beta <= omega, then alpha^T * x <= beta
dominates gamma^T * x <= omega.

Pruning out dominated inequalities is desirable.

Implied dominance by a bounded region.

Defn: If alpha^T * x <= beta is a valid inequality for
P_ch, then define the induced face of (alpha, beta)
to be F = {x in P_ch : alpha^T * x = beta}.
If F not empty, then F is called a face of P_ch and
we say that alpha^T * x <= b supports P_ch.
A face is proper if F != P_ch.

A face F of P_ch is a facet of P iff dim(F) == dim(P_ch) - 1.

Providing one facet-defining inequality for each facet
is sufficient to describe P_ch.

Convex hull: a continuous space.

Example above: dim(P_ch) == 2

Thus a facet-defining inequality must be valid and induce
a face of the proper dimension.

The purpose of facets and faces is to decide which
inequalities are necessary for the description of a
polyhedron, independent of the objective function.

If F is a facet of P_ch, then there exists at least one
linear inequality alpha^T * x <= beta (maybe infinite #)
that represents F.

Theorem: Let alpha^T * x <= beta be a valid inequality.
Then if there exists a point x in P such that alpha^T * x <= beta,
then dim({x in P_ch : alpha^t * x = beta}) <= dim(P_ch) - 1.

(provides upper bound on the dimension of a face)

Three steps in proving something is a facet in P_ch:
1) Find dim(P_ch)
-- bound from above: typically using # variables and theorem
   abt dim(polyh) + rank(A^=, b^=) = n
-- bound from below: typically by finding a number of
    affinely independent points
2) Show the ineq alpha^t * x <= beta is a valid ineq
    for P_ch; Show that no x in P has alpha^t * x >= beta
3) Find the dimension of induced face F in P_ch
-- bound from above: typically using theorem
   abt dim(polyh) + rank(A^=, b^=) = n
-- bound from below: typically by finding a number of
    affinely independent points

A valid ineq is a cutting plane if there exists an x in
P_LR such that alpha^T * x > beta

e.g.
max 5x_1 + 2x_2
s.t.
10x_1 + 2x_2 <= 23
4x_1 + 2x_2 <= 13
x_1, x_2, >= 0 and integer

Solve graphically, using cutting planes. Prove that at least
one of the cutting planes is a facet.

1) Solve the linear relaxation.
x_LP* = (5/3, 19/6); z_LP* = 44/3

2) Find a valid inequality to cut off this x_LP*.
Better off picking one that goes thru two extreme points
of P_ch.
Choose the one thru (0, 6) and (1, 4):
    2x_1 + x_2 <= 6

3) Re-solve LP with new constraint
x_LP* = (11/6, 7/3), z_LP* = 83/6

4) Find a valid inequality to cut off this x_LP*.
Choose the one thru (1, 4) and (2, 1)
    3x_1 + x_2 <= 7

5) Re-solve LP with new constraint
x_LP* = (1, 4), z_LP* = 13.
Done.

Consider 3x_1 + x_2 <= 7. Claim: It is facet-defining.

1) Find dim(P_ch).
a) Pick (0, 0), (1, 0), (0, 1)
    These are affinely independent.
    --> dim(P_ch) >= 2
b) P_ch subset-of R^2
    --> dim(P_ch) <= 2
--> dim(P_ch) == 2

2) Is it a valid inequality?
    From graph

3)
a) dim(F) induced by the ineq
describing points between points on the CH
(feasible integer points), on the equality face
(1, 4) and (2, 1)
they are affinely independent, and in F
--> dim(F) >= 1
b) If I can find another feasible point of
P or P_ch that doesn't meet an inequality,
the facet F can't be the entire space. e.g. (0, 0)
--> dim(F) < dim(P_ch)
--> dim(F) == 1
--> F is a facet.

In n dimensions....

graph:
1-2
1-3
2-3
2-4
3-4
3-5
3-7
4-5
4-7
4-8
5-7
5-8
6-7
7-8

Node packing formulation:
set of nodes s.t. no two are adjacent.

e.g. above: 2, 5, 6 are not adjacent

x_i = 1 if node i is in the packing, 0 else

max sum[i]( x_i )
s.t.
x_1 + x_2 <= 1
x_1 + x_3 <= 1
etc. (for each pair of adjacent nodes)

Call this node packing formulation P_np.
What is (P_np)_ch?

1) dim((P_np)_ch)?
a) Take (0, 0, 0, 0, 0, 0, 0, 0)
Feasible? Yes.
   Take (1, 0, 0, 0, 0, 0, 0, 0)
Feasible? Yes.
   Take (0, 1, 0, 0, 0, 0, 0, 0)
   etc.
(origin, then e_i forall i in V)

So, dim((P_np)_ch) >= n, where n = |V|

b) # vars = n, so dim((P_np)_ch) <= n
-->
dim((P_np)_ch) == n

2) valid ineq?
x_1 + x_2 + x_3 <= 1
1, 2, 3 are a clique. Call a clique k_q.

sum[i in k_q]( x_i ) <= 1
4, 5, 7, 8 are a clique.

3) Show that one of these ineq is facet-defining.

e.g. x_4 + x_5 + x_7 + x_8 <= 1.

a) Show that the induced face isn't the whole space
--> Find a point that doesn't meet it at equality,
that is feasible.
e.g. (0, 0, 0, 0, 1, 0, 0)
so dim(F) < dim((P_np)_ch)

b) Find eight affinely independent points
(so dim will be 7)
feasible, that meet the ineq at equality
[0  0  0  0  1  0  0  0
 0  0  0  0  0  1  0  0
 0  0  0  0  0  0  1  0
 1  0  0  0  1  0  0  0
 0  1  0  0  0  1  0  1
 0  0  0  0  0  0  0  1
 0  0  1  0  0  0  0  0
 0  0  0  1  0  0  1  0
 1  1  1  1  1  1  1  1]

so dim((P_np)_ch) == 7

So this clique inequality is facet-defining.

Theorem: A maximal clique inequality is
facet-defining for (P_np)_ch.

Proof: Let k be a maximal clique.
sum[i in k]( x_i ) <= 1 is valid.
0 is in P_np, and is < 1, so that
dim((P_np)_ch) <= n - 1.
The points e_i forall i in k are in P_np.
e_i + e_j forall j in V \ {k},
and there exists an i in k such that {i, j} not in E
-- Such an i exists, otherwise your clique
    isn't maximal.
So these points are feasible, and
affinely independent --> QED

Conflict graphs and hypergraphs:

e.g. 5x_1 + 7x_2 + 8x_3 + 9x_4 <= 14
     8x_1 + 6x_2 + 3x_3 + 5x_4 <= 10

In a conflict graph: nodes represent variables,
and edges represent infeasibility.

So here, edges would be:
2-3
2-4
3-4
1-2
1-3
1-4

Thus: x_1 + x_2 + x_3 + x_4 <= 1.
Is this a valid ineq?
--> Is there a feasible LR point that the ineq
     cuts off, w/o cutting off integer solns?
What about (1, 1/3, 0, 0)

Not all variables need to be involved in this.

---

e.g. 5x_1 + 7x_2 + 8x_3 + 9x_4 <= 21
     8x_1 + 6x_2 + 3x_3 + 5x_4 <= 18

Conflict graph: Now there are no pairs that
conflict. Max clique is of size 1.

Conflict hypergraph: sets of conflicting nodes
"become" edges.

"paths" in hypergraphs?
-- one vertex in common between edges?
-- all vertices except one in common between edges?

Consider an H_3 hypergraph (three nodes in an edge)
Then in the example above, we have edges:
1-3-4
1-2-4
2-3-4
E_(H_3) = { (1, 2, 4), (1, 3, 4), (2, 3, 4)}

-->
valid ineq:
e.g.
x_1 + x_2 + x_4 <= 2

Hyperclique: K_mq
m = # nodes
q = edge size
all possible edges exist
C(m, q) edges

e.g.
10x_1 + 6x_2 + 8x_3 + x_4 <= 20
5x_1 + 7x_2 + 8x_3 + 9x_4 <= 21
8x_1 + 6x_2 + 3x_3 + 5x_4 <= 18

Conflict 3-hypergraph:
1-2-3
1-2-4
1-3-4
2-3-4

Valid hyperclique inequality:
sum[i in K_mq]( x_i ) <= q - 1

x_1 + x_2 + x_3 + x_4 <= 2

Is it helping?
Find a feasible LR point that violates that
ineq.
--> (0, 1/2, 1, 1)

The more space you can cut off...

Are hyperclique inequalities facet-defining?
Yes, if each vertex is in a minimal edge.

e.g.
x_0 + 10x_1 + 6x_2 + 8x_3 + x_4 <= 20
x_0 + 5x_1 + 7x_2 + 8x_3 + 9x_4 <= 21
17x_0 + 8x_1 + 6x_2 + 3x_3 + 5x_4 <= 18

-- In conflict graph, node 0 connected to
everyone else.
-- H_3: 0-1-2, 0-2-3, 0-2-4

Conflict hypergraphs create facet-defining
inequalities. Lots of good stuff to be found.

Conflict graphs with odd cycles cause problems.
sum[i in cycle]( x_1 ) <= (n - 1) / 2

Fan: 0-1, 0-2, 0-3, 0-4
--> 5x_0 + sum[i in 1..4]( x_i ) <= 5

Wheel with hub:
...

Measuring the utility of an ineq by the dimension of its
face.

Let C_m,k be a matrix whose elements are in {0, 1}.
Let each column consist of a cyclic permutation of k
consecutive ones.

C_5,2 = [1  0  0  0  1
         1  1  0  0  0
         0  1  1  0  0
         0  0  1  1  0
         0  0  0  1  1]

* If m and k are relatively prime, then C_m,k has full rank
* rank(C_m,k) = m - gcd(m, k) + 1

e.g. G = (E, V)
A matching of G = a collection of non-adjacent edges

Let x_ij = 1 if edge (i, j) in matching, 0 else

max sum[i, j in E]( x_ij )
s.t. sum[j : (i, j) in E]( x_ij ) <= 1 forall i in V
x_ij in {0, 1} forall (i, j) in E

Objective function has no bearing on whether an ineq
is a facet.

Let P_m be the set of feasible points in a matching.
How to get to (P_m)_ch?

There are |E| variables, so dim((P_m)_ch) <= |E|.

Consider the points 0, and e_ij forall (i, j) in E.
All these are feasible, and A.I.
|E| + 1 A.I. points -> dim((P_m)_ch) == |E|.

Facet-defining ineq?

One obvious choice: fans
x_24 + x_34 + x_45 <= 1
But, often implied by the formulation.

Cliques?

Cycles?
sum[{i, j} in E]( x_ij ) <= floor(|C| / 2)
--> Are these useful?
    -- how much LR space cut off?
Odd cycles? You bet.
Even cycles don't help as much

Hole: cycle with no chords.
Proof: An odd hole can induce a facet-defining inequality.
What conditions must be met for this to be the case?


===
HW3: Hyperclique: find a point feasible to LR of the knapsack, but
violates the hyperclique ineq we found.
===

Facet-defining ineq for TSP

1 --- 2
|\   /|
| \ / |
| / \ |
3 --- 4

If formulating as:
x_ij = 1 if tour has arc (i, j), 0 else.

Feasible tours:

Biggest dimension of polyhedron for TSP:
1-2-3-4
1-2-4-3
1-3-2-4
1-3-4-2
1-4-2-3
1-4-3-2

12 1  1  0  1  0  1
13 0  1  1  1  1  0
14 1  0  1  0  1  1
23 1  0  1  0  1  1
24 0  1  1  1  1  0
34 1  1  0  1  0  1
   1  1  1  1  1  1

Some of these rows/columns are identical, indicative
of the symmetry of some of the tours.

Dropping duplicated rows and columns...
you end up with three points in P_tsp
-- they are affinely independent.
--> dim((P_tsp)_ch) == 2

Valid inequalities?

x_12 + x_13 + x_14 <= 2
Does it define a facet?

It's actually the entire space. All points of
(P_tsp)_ch meet this face at inequality.

x_12 <= 1
is facet-defining.

x_ij <= 1 is facet-defining.

Others?

x_13 + x_14 >= 1

As soon as you get into a non-fully-dimensional
polyhedron, you can find many inequalities that
induce the same face.

e.g. knapsack
19x_1 + 18x_2 + 17x_3 + 12x_4 + 12x_5 + 11x_6 + 10x_7 + 9x_8 <= 46

coefficients > 0
All a_i <= b

dim((P_kp)_ch)?
<= 8 by variables.
Take 0 and e_i --> dim((P_kp)_ch) == n

Given N = {1, ..., n}
A set C subset-of N is a cover if sum[i in C]( a_i ) > b

e.g. {1, 2, 3}
{1, 2, 3, 4}
{4, 5, 6, 7, 8}

so x_1 + x_2 + x_3 <= 2
x_1 + x_2 + x_3 + x_4 <= 3
x_4 + x_5 + x_6 + x_7 + x_8 <= 4
-->
Cover ineq: sum[i in C]( x_i ) <= |C| - 1

LR points that violate these?
1st: (1, 1, 1/2, ...)
2nd: (<1, <1, 1, 1, ...)

Not all covers are created equal.
Most useful covers are minimal covers.
Minimal cover: sum[i in C \ {j}]( x_i ) <= b
forall j in C.
(take any one element of the cover away, it's no longer
a cover)

dim(C_3): x_4 + x_5 + x_6 + x_7 + x_8 <= 4
find AI points that meet it at equality...
--> dim(F) == 4

minimal cover --> cyclic permutation of ones

e.g. knapsack
19x_1 + 18x_2 + 17x_3 + 12x_4 + 12x_5 + 11x_6 + 10x_7 + 9x_8
    + 4x_9 <= 46

a cover: {4, 5, 6, 7, 8}
it is minimal.

Extended cover: E(C)
= C union { i : a_i >= a_j forall j in C }
e.g. above: E(C) {1, 2, 3, 4, 5, 6, 7, 8}
ineq?
sum[i in E(C)]( x_i ) <= |C| - 1

Point eliminated by ineq_E(C) that isn't by ineq_C?

(0, 0, 4/17, 0, 1, 1, 1, 1, 0)

dim of F induced by ineq_E(C)?

1  0  0  0  0  0  0
2  0  0  0  0  0  0
3  0  0  0  0  0  0
4  0  1  1  1  1  0
5  1  0  1  1  1  1
6  1  1  0  1  1  1
7  1  1  1  0  1  1
8  1  1  1  1  0  1
9  0  0  0  0  0  1
   1  1  1  1  1  1

dim(F) <= 5

Extended cover is stronger ineq, but didn't increase
our dimension of our face.

Lifting:
12 types:
Up, down, middle
Sequential, simultaneous
Approximate, exact
3 * 2 * 2 = 12

e.g. Up, simultaneous, approximate lift.

Exam: Up, sequential, exact.

Lifting:
e.g. ineq_C
x_4 + x_5 + x_6 + x_7 + x_8 <= 4

"tilt" the ineq

1  0  0  0  0  0  0
2  0  0  0  0  0  0
3  0  0  0  0  0  0
4  0  1  1  1  1  0
5  1  0  1  1  1  1
6  1  1  0  1  1  1
7  1  1  1  0  1  1
8  1  1  1  1  0  1
9  0  0  0  0  0  1
   1  1  1  1  1  1

Move coefficient(s) so as to catch more points at
equality, fine more affinely indep pts.

e.g. change x_3 coeff to 2.
pull in (0, 0, 1, 0, 0, 0, 1, 1, 0)

exact: choose coeff to hit new point on face at eq.
approximate: choose coeff to make ineq stronger, but
not increase dimension of induced face.

e.g. additionally change x_2 coeff to 1.
Sequential lifting.
pick up (0, 1, 1, 0, 0, 0, 0, 1, 0)

Simultaneous lifting: set new coeffs all at same
time.

e.g. then additionally set x_1 coeff to 1
pick up (1, 0, 1, 0, 0, 0, 1, 0, 0)

Ordering in a sequential lift matters.

Tons of knapsack facets.

Algo for exact sequential lifting:
(any binary IP):

To up-lift x_1:

sum[i]( alpha_i * x_i )

solve:
max z = sum( coeffs of valid_inequalities on left side )
s.t. Ax <= b
     x_1 = 1

Then alpha_i = RHS of valid ineq - z*

Let E subset-of N and
let sum[i in N \ E]( alpha_i * x_i ) <= beta be
a valid ineq of P^ch_E
P^ch_E = { x in P^ch : x_i = 0 forall i in E }

Then solve:
z* = max sum[i in N \ E]( alpha_i * x_i )
s.t. sum[i in N \ E]( A_.i * x_i ) <= b
     x_j = 1 for some j in E
     x_i in {0, 1} forall i in N

Then the inequality:
(beta - z*) * x_j + sum[i in N \ E]( alpha_i * x_i )
<=
b
is valid
and if alpha_j != 0, then it has at least one more
dimension in P^ch_(E union {j}) than the other ineq has in
P^ch_E.

e.g.:
10x_1 + 13x_2 + 2x_3  <= 17
 4x_1 +  6x_2 + 12x_3 <= 16
    x_i in {0, 1}

x_1 <= 1 is valid.

Uplift x_2:
solve:
max x_1
s.t.
10x_1 + 13x_2 + 2x_3  <= 17
 4x_1 +  6x_2 + 12x_3 <= 16
 x_2 == 1
    x_i in {0, 1}
z* = 0 --> alpha_2 = 1 - 0 = 1
--> x_1 + x_2 <= 1

Now uplift x_3:
solve:
max x_1 + x_2
s.t.
10x_1 + 13x_2 + 2x_3  <= 17
 4x_1 +  6x_2 + 12x_3 <= 16
 x_3 == 1
    x_i in {0, 1}

z* = 1 -> alpha_3 = 0
--> x_1 + x_2 <= 1
No change!

Simultaneous lifting:
e.g.
19x_1 + 18x_2 + 17x_3 + 12x_4 + 12x_5 + 11x_6
+ 10x_7 + 9x_8 + 4x_9 <= 46

Take the cover {4, 5, 6, 7, 8}
--> x_4 + x_5 + x_6 + x_7 + x_8 <= 4

Let E = {1, 2, 3}

Look for
Alpha * (x_1 + x_2 + x_3)
+ x_4 + x_5 + x_6 + x_7 + x_8
<= 4

Two views:
-- C-space (cover space)
-- E-space

Try to figure which point biggest in (E, C)-space

Let Alpha = M   # very large
max M(x_1 + x_2 + x_3) + x_4 + x_5 + x_6 + x_7 + x_8
s.t.
19x_1 + 18x_2 + 17x_3 + 12x_4 + 12x_5 + 11x_6
+ 10x_7 + 9x_8 + 4x_9 <= 46

z* = 2M + 1
with soln x_2 = x_3 = x_8 = 1, others 0

Is M(x_1 + x_2 + x_3) + x_4 + x_5 + x_6 + x_7 + x_8 <= 4
valid?
--> No, 2M + 1 > 4
Change M...
Alpha(0 + 1 + 1) + 0 + ... + 0 + 1 = 4
--> Alpha = 1.5

max 1.5(x_1 + x_2 + x_3) + x_4 + x_5 + x_6 + x_7 + x_8
s.t.
19x_1 + 18x_2 + 17x_3 + 12x_4 + 12x_5 + 11x_6
+ 10x_7 + 9x_8 + 4x_9 <= 46

z* = 4.  Done.
--> 1.5(x_1 + x_2 + x_3) + x_4 + x_5 + x_6 + x_7 + x_8 <= 4
is valid.

Is it facet-defining?

exhibit 9 AI points so dim(F) >= 8

No Balas question for HW4.


Approximate lifting:
valid ineq:
sum[i in N \ E]( alpha_i * x_i ) <= beta

When we lift, we typically get an ineq:
sum[i in E]( alpha'_i * x_i ) +
sum[i in N \ E]( alpha_i * x_i ) <= beta'

(RHS can change when lifting, using some techniques:
    down-lifting, mid-lifting)

Approximate lifting's idea is:
alpha'_i is valid, but may be increased.

To lift, we set a var to 1 and solve another IP...
seems weird to solve IPs to help solve IPs with
stronger inequalities.

Approximate lifting: don't solve the other IP's,
instead use an approximation of that aux IP.
Willing to sacrifice the stronger ineq in order to
solve faster.
-- Ineqs generated this way can't be facet-defining

Balas' theorem:
If C = {i_1, ..., i_|C|} is a minimal cover,
and mu_h = sum[k in 1..h]( a_ik ) for h = 1, ..., |C|
and lambda = mu_|C| - b
then
-- if mu_h <= a_l <= mu_(h+1) - lambda, then alpha_l = h
-- if mu_(h+1) - lambda < a_l < mu_(h+1), then alpha_l in [h, h+1]
and at most one can have h+1 to guarantee validity

e.g.

19x_1 + 18x_2 + 17x_3 + 12x_4 + 12x_5 + 11x_6
+ 10x_7 + 9x_8 + 4x_9 <= 46

min cover: {4, 5, 6, 7, 8}

mu_h = sum[k in 1..h]( a_ik ) for h = 1, ..., |C|
lambda = mu_|C| - b

mu_0 = 0
mu_1 = 12
mu_2 = 24
mu_3 = 35
mu_4 = 45
mu_5 = 54
lambda = 54 - 46 = 8
(how much over the RHS you are with the cover coeffs)

So,
h = 0: 0 <= a_l <= 4
       4 < a_l < 12
h = 1: 12 <= a_l <= 16
       16 <= a_l <= 24
h = 2: [24, 27]
       (27, 35)
h = 3: [35, 37]
       (37, 45)
h = 4: [45, 46]
       (46, 54)

x_1 coeff 19 --> (h = 1) range -> [1, 2] --> 2*
x_2 coeff 18 --> (h = 1) range -> [1, 2] --> 1
x_3 coeff 17 --> (h = 1) range -> [1, 2] --> 1
2x_1 + x_2 + x_3 + .... <= 4


Midterm review:
-- Mail Dr. Easton with proctor info
-- Cheat sheet: 3 pg front/back
-- No calculators
-- 60 min

-- modeling
-- branch-and-bound
    -- 2D (branch on x_1 first)
    -- knapsack
-- cutting planes
    -- 2D
    -- more difficult
        -- matching or node-packing polyhedron
            -- find a valid inequality from a wheel
            -- provide conditions where wheel is
                facet-defining


-- sequential uplifting of valid ineq

If slope of obj between two of the ineq's slopes,
optimum occurs at intersection of those ineqs.
     7   2

  6   1    3

    5     4

1 = hub, spokes from 1-{2..7}
connection all around the perimeter

Within an induced subgraph -- no other edges


e.g. 10x_1 + 8x_2 + 13x_3 <= 115.2
to make this stronger:
10x_1 + 8x_2 + 13x_3 <= 115

e.g. 10.1x_1 + 8.3x_2 + 13x_3 <= 115.2
How to make this stronger?
e.g. 10x_1 + 8x_2 + 13x_3 <= 115

Chvatal-Gomory cuts:
Idea: Take any fractional coeffs on LHS, force
down to integer, force RHS down to integer

Starting with valid ineqs:
alpha_ij * x_i <= beta_j
-- Multiply both sides of all by constants u_j >= 0
-- Then floor(sum[j]( u_j * alpha_ij )) * x_i
    <=
    floor(u_j * beta_j)
    is valid.

Node-packing: hole of size 5
x_1 + x_2 <= 1
x_2 + x_3 <= 1
x_3 + x_4 <= 1
x_4 + x_5 <= 1
x_5 + x_1 <= 1

want to get:
x_1 + x_2 + x_3 + x_4 + x_5 <= 2

u_1(x_1 + x_2 <= 1)
u_2(x_2 + x_3 <= 1)
u_3(x_3 + x_4 <= 1)
u_4(x_4 + x_5 <= 1)
u_5(x_5 + x_1 <= 1)
--------------------
Setting all u_j to 1:

2x_1 + 2x_2 + 2x_3 + 2x_4 + 2x_5 <= 5

You want integers on LHS, RHS larger fractional part

u_j = 1/2
-->
x_1 + x_2 + x_3 + x_4 + x_5 <= 2.5
C-G procedure makes:
x_1 + x_2 + x_3 + x_4 + x_5 <= 2

Now, this valid ineq can be added to the others.

Rank 0 ineq: in original formulation
Rank 1 ineq: generated, as in C-G
Rank 2 ineq: combining rank 0 and rank 1 ineqs.

e.g.:
12x_4 + 12x_5 + 11x_6 + 10x_7 + 9x_8 <= 46
(0-1 knapsack cover ineq)

Goal: x_4 + x_5 + x_6 + x_7 + x_8 <= 4

1/3:
4x_4 + 4x_5 + 3x_6 + 3x_7 + 3x_8 <= 15

1/2:
2x_4 + 2x_5 + x_6 + x_7 + x_8 <= 7

combine the first one and the 1/3 one:
1/13:
16/13x_4 + 16/13x_5 + 14/13x_6 + 13/13x_7 + 12/13x_8
<=
61/13
-->
x_4 + x_5 + x_6 + x_7 <= 4. Ugh. Tautology.

e.g. clique inequality, for K_4, node packing polyhedron
x_1 + x_2 <= 1
x_1 + x_3 <= 1
x_1 + x_4 <= 1
x_2 + x_3 <= 1
x_2 + x_4 <= 1
x_3 + x_4 <= 1

goal: x_1 + x_2 + x_3 + x_4 <= 1

Considering only 1-2, 1-3, 1-4:
mult them by 1/2:

x_1 + x_2 + x_3 <= 1.5
Good, the K_3 ineq.
also,
x_1 + x_2 + x_4 <= 1
x_1 + x_3 + x_4 <= 1
x_2 + x_3 + x_4 <= 1

sum them all:

3x_1 + 3x_2 + 3x_3 + 3x_4 <= 4
x_1 + x_2 + x_3 + x_4 <= 4/3
Rank 2 ineq.
(in general how do you know it's rank 2?)

Generally, the deeper the rank, the stronger the ineq.

Can get rank-3 ineq for K-5 similarly
Could it have been rank 2?


e.g. knapsack problem:
Result: finding optimal soln to KP is NP-hard even if
every exact sequentially uplifted inequality is
included.
-->
There exist lots of other facets.

Exact lifting over general int vars.


Project:
Create branching style
Create own cutting planes

1) Implement feasibility cuts
    -- e.g. TSP
    -- OPL, C, Python
2) Multiple knapsack problem
    -- Solve LR
    -- Find a violated cover
    -- Add cover cuts (extended cover cuts)
    -- Re-solve LR
    -- ~ 3 times
    -- Solve IP
    -- Compare, decide whether the cuts actually help
3) Graph coloring
    -- Solve LR
    -- Find violated ineq like for cliques, etc.
    -- add those cuts, re-solve
    -- ~ n times
    -- Solve IP
    -- Compare, decide whether the cuts actually help



TSP formulations:

x_ij = 1 if in the tour, 0 else
sum[i]( x_ij ) == 1 forall j
sum[j]( x_ij ) == 1 forall i
But disconnected subtours!

1  --- 2 --- 3 --- 4 --- 1

5 --- 6 --- 7 --- 8 --- 9 --- 5

To elim subtours, need to take the sum of
all possible x_ij in the subtour, and
constrain to <= |subtour| - 1

Classical:
find a subtour, draw an arc around it, and
need at least two edges out
(check Nemhauser/Wolsey)


Chvatal-Gomory cuts:
e.g.
15x_1 + 17x_2 <= 96
14x_1 +  7x_2 <= 47

How to get to something like
x_1 + x_2 <= ?

u_1 (15x_1 + 17x_2 <= 96)
u_2 (14x_1 +  7x_2 <= 47)

What abt u_1 == 3/58, u_2 == 1/58

59/58 x_1 + 58/58 x+2 <= 335/58
flooring:
x_1 + x_2 <= 5

Cuts off LR point (11/15, 5)

Good method to generate these?

Theorem: All valid inequalities are either
C-G inequalities or dominated by C-G
inequalities.

1 -- 2 -- 3 -- 1 : K_3

x_1 + x_2 <= 1
x_2 + x_3 <= 1
x_1 + x_3 <= 1

Multi all by 1/2, add them up:
x_1 + x_2 + x_3 <= 1.5
floor RHS:
x_1 + x_2 + x_3 <= 1

This is a rank-1 inequality.

Rank 0: original inequalities of prob
Rank 1: Make new one that didn't exist,
using C-G process.
Rank 2: is not a rank 0 or rank 1
C-G inequality, but can be made from rank 0
and rank 1 C-G inequalities.
Rank k: is not a rank 0 thru k-1 C-G ineq,
but can be made from rank 0 thru rank k-1
C-G inequalities.

Extremely difficult to prove an exact rank
on a C-G ineq.
Easier to get an upper bound on the rank.

K_2 = rank 0
K_3 = rank 1
K_4, K_5 = rank 2
K_6 thru K_9 = rank 3

K_10: x_1 + ... + x_10 <= 1
C(10, 5) ineqs = 252
x_1 shows up C(9, 4) = 126 times
Let u = 1/126
-->
x_1 + ... + x_10 <= 252/126 = 2
Can't get K_10 with rank 3 ineqs.
Go to rank 4.
Rank 4 continues up to and including K_17
2(k - 1) - 1

Ballpark the rank of a K_2073 ineq?
log2(2073) ~ 11

upper bound is log2(n)

The higher the rank you can get, the stronger
the valid ineq is.


e.g.
max x_1 + ... + x_n
2x_1 + 2x_2 + ... + 2x_n <= n
where n is odd

Symmetry cuts:
make an invalid cut -- eliminate some feasible
solutions, so long as you don't cut off an optimum

what abt: x_1 >= x_2?
x_2 >= x_3?
...
x_(n-1) >= x_n

Now, LR is (1, 1, 1, 1, ..., 1, 1/2, 0, 0, ..., 0)
Lop off whole right branch when branch on x_(n+1/2)
Left branch -- we're integer. done.

e.g. VRP:
x_ijk = 1 if truck k goes from i to j, 0 else
Trucks are interchangeable!
sum[i, j]( x_ijk ) <= sum[i, j]( x_ij(k+!) )

go from hub (0) to lowest possible number destination

Must argue that symmetry cuts are independent of each other


Optimality cuts:
Eliminate non-optimal solns.
These are non-valid cuts, they will cut off feasible
integer points; but they're known to be non-optimal.

e.g. in branch-and-bound, we fathom when can't do better
than bound.

e.g. traveling tournament problem
Find min distance for a double round-robin
e.g. NL East: ATL, MIA, MTL, NYM, PHI, PIT
Every team plays every other team, once on road,
once away.
2 or three aways in a row (maybe 1-level homestand?)
2 or three homes in a row (maybe 1-level road trip?)

Find a feasible schedule, minimize total distance.

-- Found best tour for every team, by solving IP
ATL: 1500 mi
MIA: 1900 mi
NYM: 1200 mi
PHI: 1300 mi
...

16 teams:
Partial soln: Optimal soln has five trips for everyone:
    2763
Best 6-trip schedule:
    3217

Add cuts into IP
Manually argue that no optimal soln will exist via these
cuts.

e.g.
max 5x_1 + 4x_2 + 3x_3
s.t. 3x_1 + 2x_2 + 4x_3 <= 9
x_i >= 0 and integer

add x_1 >= x_3
    x_2 >= x_3

e.g. VRP
Symmetry cuts:
-- Truck 1 does the most visits
-- Truck 1 must visit customer 1
These two cannot be applied together.

You can tell if symmetry cuts/optimality cuts
didn't work by....?
-- Solve small problems
    -- CPLEX
    -- and with cuts
-- If solns the same, gives you more confidence that your
    model is correct.

Midterm:
80 A, 60 B

Get good at solving 2-D LR by hand
Get good at 2-D B-and-B by hand
Get good at 2-D cutting planes


Modular arithmetic
=====
a mod b == remainder of a / b

Modular cuts:
for equality constraints only.

Let P = {x in Z+^n : sum[j in N]( a_j * x_j ) == a_0 }
where a_j in R forall j

Let d be a positive integer, and
P_d^ch = { x in Z+^n : sum[j in N]( a_j * x_j ) == a_0 + kd }
for some integer k.

If we obtain a valid ineq for P_d^ch, then we have a valid
inequality for P_d.

Given an equality constraint
sum[j in N]( a_j * x_j ) == b
with x_j in Z+

Given some d in Z+, let r_j be the remainder when a_j is divided
by d,
and let s be the remainder when b is divided by d.

Then sum[j in N]( r_j * x_j ) = s (mod d)
and since s < d, and sum[j in N]( r_j * x_j ) >= 0,
implies
sum[j in N( r_j * x_j ) >= s.

This is a modular cut.

e.g.
2x_1 + 12x_2 + 16x_3 + 3x_4 = 31
x_4 must be >= 1 and odd, because it's the only odd coeff that can
help meet the RHS.

mod'ing by 3:
2x_1 + x_3 >= 1
           (== 1 or 4, or 7, or 10, ...)

e.g.
63x_1 + 25x_2 + 37x_3 + 19x_4 + 9x_5 - 5x_6 = 79
mod 5 modular cut:
3x_1 + 0x_2 + 2x_3 + 4x_4 + 4x_5 - 0x_6 >= 4
Does this cut off an LR point?
(..., x_2 = 79/25 ; satisfies 1st, but not the cut)

When looking for a strong modulus:
Goals: Small coeffs on LHS are beneficial;
larger coeffs on RHS better.
No zero on RHS.

mod 3 modular cut:
0x_1 + x_2 + x_3 + x_4 + 0x_5 + x_6 >= 1
x_2 + x_3 + x_4 + x_6 >= 1

mod 9:
7x_2 + x_3 + x_4 + 4x_6 >= 7


Gomory cuts:
Take any fractional row RHS in final simplex,
Mod 1 and cut.

sum[j in N( r_j * x_j ) >= s
becomes:
sum[j in N][( a_j - floor(a_j) ) * x_j ] >= b - floor(b)

e.g.
max z - x_1 + x_2 = 0
s.t. 2x_1 + 3x_2 + s_1 = 8
     3x_1 + 2x_2 + s_2 = 8
     x_1 + x_2 - e_1 = 1

z  x_1   x_2   s_1   s_2    e_1   RHS
=====================================
1   0     0    1/5   1/5     0    16/5
0   1     0   -2/5   3/5     0     8/5
0   0     1    3/5  -2/5     0     8/5
0   0     0   -1/5  -1/5     1    11/5

Pick row 1:
x_1 - 2/5s_1 + 3/5s_2 = 8/5

mod by 1:
0x_1 + 3/5s_1 + 2/5s_2 >= 3/5

Does this cut off a point?
current optimum:
z* = 16/5,
x_1 = 8/5, x_2 = 8/5, s_1 = 0, s_2 = 0, e_1 = 11/5

Can apply these successive to LR, before branching

Add this Gomory cut to tableau:

z  x_1   x_2   s_1   s_2    e_1   e_2   RHS
===========================================
1   0     0    1/5   1/5     0     0    16/5
0   1     0   -2/5   3/5     0     0     8/5
0   0     1    3/5  -2/5     0     0     8/5
0   0     0   -1/5  -1/5     1     0    11/5
0   0     0    3/5   3/5     0    -1     3/5

No basis after adding this row: pivot

z  x_1   x_2   s_1   s_2    e_1   e_2   RHS
===========================================
1   0     0    1/5   1/5     0     0    16/5
0   1     0   -2/5   3/5     0     0     8/5
0   0     1    3/5  -2/5     0     0     8/5
0   0     0   -1/5  -1/5     1     0    11/5
0   0     0   -3/5  -3/5     0     1    -3/5

Dual simplex the negative RHS out:

Row 4
Pivot on a negative column value:
s_2:

z  x_1   x_2   s_1   s_2    e_1   e_2   RHS
===========================================
1   0     0     0    0       0   1/3     3
0   1     0    -1    0       0     0     1
0   0     1     1    0       0  -2/3     2
0   0     0     0    0       1   1/3     2
0   0     0     1    1       0   5/3     1

Back-substituting the Gomory cut involving
slack/surplus vars into x_1/x_2 vars.






































.
